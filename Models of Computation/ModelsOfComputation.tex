\documentclass[11pt]{article}
\usepackage{imakeidx}
\usepackage{geometry}
\geometry{a4paper,
total={170mm, 257mm},
left = 30mm,
right = 30mm,
bottom = 30mm,
top = 30mm
}
\title{Models of Computation \linebreak Revision Notes}
\author{James Brown}
\makeindex
\begin{document}
	\pagenumbering{gobble}
	\maketitle
	\newpage
	\tableofcontents
	\newpage
	\pagenumbering{arabic}
	
	\section{Introduction}
	These are notes I have written in preparation for the upcoming 2017 Models of Computation exam. This year the module was run by Paul Levy (P.B.Levy@cs.bham.ac.uk).
	\linebreak
	This module is about problems and \textit{computers}. We ask ourselves:
	\begin{itemize}
		\item What problems can be solved on a computer?
		\item What problems can be solved on a computer with finitely many states?
		\item What problems can be solved on a computer with only finitely many states, but also a stack of unlimited size?
		\item What problems can be solved on a computer with only finitely many states, but also a tape of unlimited size that it can read and write to?
		\item What problems can be solved \textit{fast} on a computer?
		\item What does "fast" mean anyway?
		\item What does \textit{computer} mean anyway?
	\end{itemize}
	
	\section{Language Membership Problems and Regular Expressions}
	\subsection{Language Membership Problems}
	Suppose we have a set of characters $\Sigma$, which we will call the \textit{alphabet}\index{alphabet}. A \textit{word}\index{word} is a finite sequence of characters, and we write $\Sigma^{*}$ for the set of all words. We can \textit{concatenate}\index{concatenate} words. A \textit{language}\index{language} is a set of words and a subset of $\Sigma^{*}$. Given a word, we want to know is it in the language or not? If we take an example alphabet ${a, b, c}$, here are some languages:
	\begin{itemize}
		\item All words which contain exactly 3 \textit{b}'s
		\item All words whose length is prime
		\item All words that have more \textit{b}'s than \textit{a}'s
		\item The words \textit{abc}, \textit{bac} and \textit{cb}
		\item No words at all
		\item The empty word
	\end{itemize}
	
	These examples are largely pretty useless, but this problem does have real world applications such as 
	\begin{itemize}
		\item Java has rules about what you can call a variable. Is the word read by the compiler a valid variable name?
		\item A user makes an account and enters a password, is it valid?
		\item A student has submitted code for an assignment, is it correct?
		\item Will this code crash when it's run?
	\end{itemize}
	
	In each one of these examples, we are provided with a word and we want to know whether it is an acceptable word. We want to make a computer tell us the answer.
	
	\subsection{Regex}
	\textbf{Regular Expressions}\index{Regular Expressions} are a useful notation for describing languages. We write Empty for the language consisting of no words (the empty set). We write \textit{a} for the language consisting of just the single-character a, and $\epsilon$ for the language consisting of just the empty word. If we have a language \textit{\textbf{L}} and \textit{\textbf{L'}}, we write \textit{\textbf{LL'}} for the set of words that are a concatenation of a word in \textit{\textbf{L}} and a word in \textit{\textbf{L'}}. We can also write \textit{\textbf{L|L'}} for the set of words that are in \textit{\textbf{L}} or \textit{\textbf{L'}} - the union of the two languages. We write \textit{\textbf{L*}} for the set of words that are a concatenation of some number of words in \textit{\textbf{L}} (some number may be 0).
	Just like arithmetic, regular expressions have precedence rules. $*$ has the highest precedence, then juxtaposition and then $|$.
	
	\par 
	Regular expressions in theoretical computer science mean an expression built from the above operations and nothing more. Regular expressions are used much more widely in programming with far more operations, but they cannot be used in the module. For example, $+$ is a very common operation but not available to us.
	
	
	\section{Finite State Automata}

	\section{Regular Languages}
	
	\section{Bisimulation and Minimisation}
		
	\section{The Halting Problem}
	In Computer Science there are many problems that we encounter. These all have an input (some string, a number, three strings etc.) and an output. Often this output is yes or no, but it may be a number or string or some other value. If a problem returns a yes or no result, then it is a decision problem\index{decision problem}. We have to draw a distinction between problems\index{problem} and instances\index{instance}. 'Is the word $abbab$ accepted by the regexp $ab*(ab*|b)$?' is an instance of a more general problem 'Is a word $w$ accepted by the regexp $ab*(ab*|b)$?'. Even more generally we could describe this problem as 'Given a word $w$ and a regexp $E$, is $w$ accepted by $E$?'.
	
	\par 
	Typically we want to consider problems which have a countably infinite set of acceptable inputs and acceptable outputs. Refer to Mathematical Techniques for Computer Science to see how we can ensure something is countably infinite. A problem can also be called a function\index{function}, and we can also describe it as a subset of the set of inputs. 
	\begin{itemize}
		\item Problem: given a positive integer, is it prime?
		\item The function that maps a positive integer to 'true' if it's prime and 'false' otherwise
		\item The subset of the set of positive integers consisting of all prime integers
	\end{itemize}
	If the set of inputs is the set of words over some alphabet, then the subset will be a language.
	
	\par
	\textbf{Key concepts:}
	\begin{itemize}
		\item A decision problem (a problem which returns a yes or no answer) is decidable if it can be solved on a computer.
		\item A function is computable if it can be computed on a computer.
		\item A subset of the set of inputs (a language) is decidable if the corresponding decision problem can be solved on a computer.
	\end{itemize}
	
	We still haven't come up with a definition for \textit{computer} yet! We get around this for now by saying a problem is 'Java-decidable' or 'Java-computable' for example, meaning that we can accomplish the task with a Java program.

	\subsection{Reducing a problem to another problem to solve the Halting problem}
	Suppose we have two problems - $P$ and $Q$. If we can show how to solve $Q$ using a black box which solves $P$ then we can say that we have reduced\index{reduce} the problem $Q$ to the problem $P$. If we can reduce $Q$ to $P$ then if $P$ is decidable\index{decidable}, $Q$ is decidable and if $Q$ is undecidable\index{undecideable}, $P$ is undecidable.
	
	\par
	Given a nullary Java method such as the one below, can we tell if it will terminate or not? We keep things simple by assuming integers are unbounded, no exceptions are thrown and any such method when called either terminates or hangs forever).
	\begin{verbatim}
		void f (){
		    ...
		}
	\end{verbatim}
	
	This is an example of the \textbf{Halting Problem}\index{halting problem}. Turing proved that the halting problem was undecidable. To prove this, we assume that it is decidable.
	
	\begin{enumerate}
		\item Consider the \textbf{unary halting problem}. Given a unary Java method
		\begin{verbatim}
			void f (String x) {
			    ...
			}
		\end{verbatim}			
		and a string $y$, does \texttt{f} terminate when called with $y$? We reduce the unary halting problem to the nullary one. Given the unary method \texttt{f} and a string $x$, obtain a nullary method \texttt{g} by taking the code of \texttt{f} and replacing \texttt{x} with $y$ - that is substitute in the argument values. Then, \texttt{g} terminates when called if \texttt{t} terminates when called with argument $y$. Since we assume the nullary halting problem is solvable, the unary one is too. This gives us a program
		\begin{verbatim}
			boolean haltcheck (String somemethod, String y)
		\end{verbatim}
		
		where \texttt{somemethod} is the body of a unary method. When we apply with $M$ and $y$ this method returns true when $M$ applied to $y$ terminates, otherwise it returns false.
	
	\item We build on this method further
		\begin{verbatim}
			void hangcheck (String somemethod, String y) {
			   if haltcheck(somemethod, y) {
			      while true {}
			   } else {
			      return;
			   }
			}
		\end{verbatim}	
		
		This method when applied to $M$ and $y$, hangs if $M$ applied to $y$ terminates, otherwise it returns.
				
	\item We build on this even further with a new program
		\begin{verbatim}
			void doublehang (String y) {
			    haltcheck(y, y)
			}
		\end{verbatim}
		
		This method when applied to $y$ (the body of the unary method), will hang if $y$ applied to $y$ terminates, otherwise it returns.
	
	\item Finally, let $z$ be the body of \texttt{doublehang}. We see that \texttt{doublehang}, when applied to $z$, terminates if and only if it hangs. This is a contradiction, so there cannot be any program which solves the halting problem.	
	
	\end{enumerate}
		
	\section{Properties of Code}
	
	\subsection{Rice's Theorem}
	Rice's theorem\index{rice's theorem} states that every non-trivial semantic property of code is undecidable. We define a trivial property\index{trivial property} is one which either holds for everything or holds for nothing.
	\par 
	To prove Rice's theorem, we let $\alpha$ be a non-trivial semantic property of code and let \texttt{alwayshang} be a piece of code that always hangs regardless of argument. We say that \texttt{alwayshang} doesn't satisfy $\alpha$, and since $\alpha$ is non-trivial we can say that there is another piece of code $C$ that does. For any nullary program $P$, we form $F(P)$ by inserting $P$ at the start of the code $C$.
	\begin{itemize}
		\item If $P$ terminates, then $F(P)$ has the same semantics as $C$. Because $\alpha$ is semantic and $C$ satisfies $\alpha$, $F(P)$ does too.
		\item If $P$ hangs, then $F(P)$ has the same semantics as \texttt{alwayshang}. Since $\alpha$ is semantic and \texttt{alwayshang} doesn't satisfy $\alpha$, $F(P)$ also doesn't.
	\end{itemize}
	
	In short, $P$ will terminate if and only if $F(P)$ satisfies $\alpha$. This means that if we can test for $\alpha$, we can also test whether $P$ terminates by testing if $F(P)$ satisfies $\alpha$. We've already proven that we can't prove $P$ terminates, so we must not be able to test for $\alpha$ - meaning $\alpha$ is undecidable\index{undecidable}.
	
	\section{Turing Machines}
	In 1936, Alan Turing\index{alan turing} invented the \textbf{turing machine}\index{turing machine}. Turing machines are very simple computers, and have a very limited set of instructions that they can execute. They have finitely many states, but also have an infinite tape which they can compute upon. Because of this, a Turing machine is an idealized computer and can never exist in the physical world. Turing machines are very convenient for analysing the running times of algorithms. Firstly, the time taken for an algorithm scales straightforwardly as the size of the input increases. They typically tend to treat inputs of size ten or one million in the same way. Secondly, every step of computation is made explicit in a very conservative way.
	
	\par 
	Turing machines have finitely many \textbf{states} and an infinite tape, with a \textbf{head}\index{head} which sits over one space of the tape. They also have a finite tape alphabet $T$, and each space on the tape contains a letter which is contained in $T$. $T$ also contains the blank character, $\textvisiblespace \in T$, which is particularly important. All but finitely many spaces on the tape are blank - it never happens that infinitely many spaces contain actual, non-blank, characters. The two properties of a Turing machine - unlimited time and unlimited space - are essential.
	
	\par 
	Let $T$, the \textbf{tape alphabet} be a finite set of characters. Let $R$ be a finite set of \textbf{return values}. This is commonly just a singleton set, which would be analagous to \texttt{void} in Java, and simply tells us whether the prorgam returns (halts, terminates) or runs forever. It may also be a larger set, like a two-element set analagous to \texttt{boolean} for example. A Turing machine over $T$ and $R$ consists for the following data:
	\begin{itemize}
		\item A finite set $Q$ of states
		\item An initial state\index{initial state} $q_{0} \in Q$
		\item A transition function\index{transition function} $\delta$ from $Q$ to the following set of behaviours:
			\begin{itemize}
				\item $(T \rightarrow Q)$ (read from current position)
				\item $(T \times Q)$ (write to current position)
				\item $Q$ (move left)
				\item $Q$ (move right)
				\item $Q$ (do nothing)
				\item $R$ (stop)
			\end{itemize}
	\end{itemize}
	
	\section{Church's Thesis}
	\textit{'What ever can be done by any computational device can be done by a Turing machine'}
	\linebreak
	
	\par Church's thesis cannot be proven - it's entirely possible for someone to invent a new way of computation which extends the capabilities of programs as we know them. On the other hand, nobody has been able to come up with an alternative to Turing machines - the more time that passes to more plausible Church's thesis becomes.
	
	\section{Complexity and P}
	
	\section{NP}
	
	\section{Lambda-calculus}
	Alonzo Church developed a notation for arbitrary \textbf{functions} called $\lambda$-calculus. It is an extremely economical notation but at first sight somewhat cryptic, which stems from its origins in mathematical logic. Expressions in $\lambda$-calculus are written in strict prefix form. Further, function and argument are simply written next to each other without brackets around the argument.
	
	
	\subsection{Church-Rosser Theorem}
	\textit{'If a term M can be reduced (in several steps) to terms N and P, there there exists a term Q to which both N and P can be reduced (in several steps)}
	\linebreak
	\par This is sometimes known as confluence. Regardless of the order in which we decide to reduce our lambda calculus expression, we will always be able to arrive at the same term. This makes perfect sense - when evaluating an expression with arithmetic terms, we cannot get two different answers dependent on the order of evaluation. It follows that we get this corollary:
	\linebreak	
	
	\textit{'Every $\lambda$-term has at most one normal form'.}
	
	\par
	We can prove this. Assume there are two normal forms (for the case of contradiction) N and P to which are certain term M reduces. By the theorem of Church and Rosser there is a term Q to which both N and P can be reduced to. However, as we have assumed N and P are in their normal forms they don't allow any further reductions. The only possible interpretation for this is that N = P = Q.
	
	\subsection{Typed Lambda-calculus}
	Currently there is nothing in the grammar of lambda calculus that restricts us from forming awful terms. It would be completely possible to form $\sin \log$ at the moment - the sine function applied to the logarithm function. This is obviously impossible and any programming language would reject this as incorrectly formed. We are currently missing the notion of types, which represent what kind of arguements the function will accept and what it expects to return.
	
	\par 
	We can form the language for expressing these types very easily. We begin with base types such as \texttt{int} and \texttt{real}. On top of this we then form function types. This gives us the following grammar which is called the \textbf{system of simple types}\index{system of simple types}:
	
	\[ \tau ::= c \; | \; \tau \rightarrow \tau \]
	
	\par In this grammar, the value c is used as a placeholder for all of our base types we wish to include. Now we can form function types, we would give the type of the sine function as $\texttt{real} \rightarrow \texttt{real}$, which makes it obvious that it cannot accept the logarithm function as an argument. Using the type system that we have defined, we can create restrictions on what kind of terms are valid (or \textbf{well-typed}). We do this by an inductive definition:
	\begin{itemize}
		\item \textbf{Base Case}: For every type $\sigma$ and every variable $x$, the term $x:\sigma$ is well typed and has type $\sigma$.
		\item \textbf{Function formation}: For every term $M$ of type $\tau$, every variable $x$, and every type $\sigma$, the term $\lambda x:\sigma .M$ is well-typed and has type $\sigma \rightarrow \tau$
		\item \textbf{Application}: If $M$ is well-typed of type $\sigma \rightarrow \tau$ and $N$ is well-typed of type $\sigma$ then $M N$ is well-typed and has type $\tau$
	\end{itemize}	
	
	
	\newpage
	\listoffigures
	\printindex
\end{document}
